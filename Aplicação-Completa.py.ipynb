{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OpuWom6z-jYQ0QSV4ODwWdlSyIoSBgMU","timestamp":1729986022817}],"authorship_tag":"ABX9TyMCqsilnfniUP7OiA+AAgdi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxtYPEpipRkX","executionInfo":{"status":"ok","timestamp":1729982696555,"user_tz":180,"elapsed":10714,"user":{"displayName":"Cesar Ricardo","userId":"10597880765894760911"}},"outputId":"6e8052a7-0d1a-43af-89b9-c12226833159"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n","Collecting openai\n","  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Collecting langchain-core<0.4.0,>=0.3.12 (from langchain-openai)\n","  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (6.0.2)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain-openai)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.12->langchain-openai)\n","  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (24.1)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (9.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-openai)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain-openai)\n","  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain-openai)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n","Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: orjson, jsonpointer, jiter, h11, tiktoken, requests-toolbelt, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-openai\n","Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.13 langchain-openai-0.2.3 langsmith-0.1.137 openai-1.52.2 orjson-3.10.10 requests-toolbelt-1.0.0 tiktoken-0.8.0\n"]}],"source":["!pip install requests beautifulsoup4 openai langchain-openai"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def extract_text_from_url(url):\n","  response = requests.get(url)\n","\n","  if response.status_code == 200:\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    for script_or_style in soup(['script', 'style']):\n","      script_or_style.decompose()\n","    texto = soup.get_text(separator= '')\n","\n","  else:\n","      print(f\"Failed to fetch the URL. Staus code: {response.status_code}\")\n","      return None\n","\n","\n","  text = soup.get_text()\n","  return text\n","\n","  extract_text_from_url('https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo')"],"metadata":{"id":"G8HobwHKv77s","executionInfo":{"status":"ok","timestamp":1729983627005,"user_tz":180,"elapsed":311,"user":{"displayName":"Cesar Ricardo","userId":"10597880765894760911"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def extract_text_from_url(url):\n","  response = requests.get(url)\n","\n","  if response.status_code == 200:\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","    for script_or_style in soup(['script', 'style']):\n","      script_or_style.decompose()\n","    texto = soup.get_text(separator= '')\n","    #limpar texto\n","    linhas = (line.script() for line in texto.splitlines())\n","    parts = (phrase.script() for line in linhas for phrase in line.script(\"  \"))\n","    texto_limpo = '\\n'.join(part for part in parts if part)\n","    return texto_limpo\n","  else:\n","      print(f\"Failed to fetch the URL. Staus code: {response.status_code}\")\n","      return None\n","\n","\n","  text = soup.get_text()\n","  return text\n","\n","  extract_text_from_url('https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo')"],"metadata":{"executionInfo":{"status":"ok","timestamp":1729983690513,"user_tz":180,"elapsed":303,"user":{"displayName":"Cesar Ricardo","userId":"10597880765894760911"}},"id":"fT4Np9gPEBD3"},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from langchain_openai.chat_models.azure import AzureChatOpenAI\n","\n","client = AzureChatOpenAI(\n","    azure_endpoint= \"https://openai-dio-001.openai.azure.com/\",\n","    api_key= \"ff73249731ec438191ea328f14b294d8\",\n","    api_version= \"2024-04-09-preview\",\n","    deployment_name= \"gpt-4-turbo\",\n","    max_retries=0\n",")\n","\n","def translate_article(text, lang):\n","  messages = [\n","      (\"system\" , \"Você atua como tradutor de textos\"),\n","      (\"user\", f\"Traduza o {text} para o idioma {lang} e responda em markdown\")\n","  ]\n","\n","  response = cliente.invoke(messages)\n","  print(response.content)\n","  return response.content\n","\n","  translate_article(\"Let's see if the deployment was succeded.\", \"portugues\")"],"metadata":{"id":"aLu0GD9WwOWu","executionInfo":{"status":"ok","timestamp":1729983665986,"user_tz":180,"elapsed":342,"user":{"displayName":"Cesar Ricardo","userId":"10597880765894760911"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'\n","text = extract_text_from_url(url)\n","article = translate_article_(text, \"pt-br\")\n","\n","print(article)"],"metadata":{"id":"3R4cKebMAz9s"},"execution_count":null,"outputs":[]}]}